{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed57a9a6",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "## Nakiyah Dhariwala\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4cbe72",
   "metadata": {},
   "source": [
    "### Final Dataset Selection:\n",
    "https://archive.ics.uci.edu/dataset/320/student+performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58864a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alepython\n",
      "  Cloning https://github.com/MaximeJumelle/ALEPython.git (to revision dev) to /private/var/folders/f4/vybgzbbx1sg165hn_kn98j0m0000gn/T/pip-install-kcdfkda_/alepython_f1d1e00b86024bc9b1906b175a4c83e1\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/MaximeJumelle/ALEPython.git /private/var/folders/f4/vybgzbbx1sg165hn_kn98j0m0000gn/T/pip-install-kcdfkda_/alepython_f1d1e00b86024bc9b1906b175a4c83e1\n",
      "  Resolved https://github.com/MaximeJumelle/ALEPython.git to commit 286350ab674980a32270db2a0b5ccca1380312a7\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: loguru>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (0.7.3)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (3.9.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (2.2.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (1.11.4)\n",
      "Requirement already satisfied: seaborn>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from alepython) (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib>=2.2.3->alepython) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.22.0->alepython) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=0.22.0->alepython) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=2.2.3->alepython) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/MaximeJumelle/ALEPython.git@dev#egg=alepython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6c4fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from alepython import ale_plot\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "\n",
    "# Set options to display all rows and columns\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141206c0",
   "metadata": {},
   "source": [
    "### Step 1: loading and viewing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92d85ad",
   "metadata": {},
   "source": [
    "I am just doing initial EDA to check for missing values, incorrect data types and to see what the data contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632904bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'student/student-mat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading the math dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstudent/student-mat.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m;\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'student/student-mat.csv'"
     ]
    }
   ],
   "source": [
    "# Loading the math dataset\n",
    "df = pd.read_csv(\"student/student-mat.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cf5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look\n",
    "print(\"The dimensions of this dataset are:\", df.shape)\n",
    "print(\"The columns for this dataset are\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16259ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b981ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75baa776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check for numeric values\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7cbde",
   "metadata": {},
   "source": [
    "There are no missing values so we can proceed with the next step of looking at and chaing the data types of features if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1057f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b080477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the distribution of the target variable\n",
    "\n",
    "plt.hist(df[\"G3\"], bins=20, edgecolor=\"k\")\n",
    "plt.xlabel(\"Final Math Grade (G3)\")\n",
    "plt.ylabel(\"Number of Students\")\n",
    "plt.title(\"Distribution of Final Math Grades\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960fb11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d255529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am explicitly defining columns and its types for my convenience\n",
    "\n",
    "target = \"G3\"\n",
    "\n",
    "\n",
    "binary_cols = [\n",
    "    \"schoolsup\",\n",
    "    \"famsup\",\n",
    "    \"paid\",\n",
    "    \"activities\",\n",
    "    \"nursery\",\n",
    "    \"higher\",\n",
    "    \"internet\",\n",
    "    \"romantic\",\n",
    "]\n",
    "\n",
    "ordinal_cols = [\n",
    "    \"age\",\n",
    "    \"Medu\",\n",
    "    \"Fedu\",\n",
    "    \"traveltime\",\n",
    "    \"studytime\",\n",
    "    \"failures\",\n",
    "    \"famrel\",\n",
    "    \"freetime\",\n",
    "    \"goout\",\n",
    "    \"Dalc\",\n",
    "    \"Walc\",\n",
    "    \"health\",\n",
    "    \"absences\",\n",
    "    \"G1\",\n",
    "    \"G2\",\n",
    "]\n",
    "\n",
    "nominal_cols = [\n",
    "    \"school\",\n",
    "    \"sex\",\n",
    "    \"address\",\n",
    "    \"famsize\",\n",
    "    \"Pstatus\",\n",
    "    \"Mjob\",\n",
    "    \"Fjob\",\n",
    "    \"reason\",\n",
    "    \"guardian\",\n",
    "]\n",
    "\n",
    "# explicitly defining the dataset and the predictor variable\n",
    "predictors = binary_cols + ordinal_cols + nominal_cols\n",
    "data = df[predictors + [target]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef90903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping binaries to yes/no\n",
    "yesno_map = {\"yes\": 1, \"no\": 0, \"Yes\": 1, \"No\": 0}\n",
    "for col in binary_cols:\n",
    "    data[col] = data[col].map(yesno_map).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinals + binaries + target -- to be used in correlation\n",
    "num = data[ordinal_cols + binary_cols + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9accc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlations\n",
    "corr_p = num.corr(method=\"pearson\")\n",
    "\n",
    "# Sort by absolute correlation with G3\n",
    "cw = corr_p[\"G3\"].drop(\"G3\")\n",
    "order = cw.abs().sort_values(ascending=False).index\n",
    "corr_with_G3 = pd.DataFrame({\"corr\": cw.loc[order], \"abs_corr\": cw.abs().loc[order]})\n",
    "print(corr_with_G3.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba31e0",
   "metadata": {},
   "source": [
    "### Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d31c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating heatmap of top correlates\n",
    "topk = order[:10].tolist() + [\"G3\"]\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    corr_p.loc[topk, topk],\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    square=True,\n",
    ")\n",
    "plt.title(\"Pearson correlation (top features vs G3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b28e5c",
   "metadata": {},
   "source": [
    "We can see very strong correlations for G1 and G2 with G3, which makes sense since prior grades would dominate and be a good predictor of the final grade. Students who have more past failures also have a tendency to perform worse (-0.36). Interestingly, mother's education does have a small positive effect (0.22). Lifestyle factors such as going out with friends, being in a relationship, or having longer travel times show only weak negative links, while father’s education and alcohol consumption appear to have little effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32065a2",
   "metadata": {},
   "source": [
    "### Building Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fde13b",
   "metadata": {},
   "source": [
    "I am going to perform a Random Forest regressor for this dataset since it would be able to model nonlinear relationships and interactions. It also conventiently handles small datasets without requiring heavy hyperparameter tuning. \n",
    "\n",
    "However, before running the Random Forest regressor, I am going to intentionally remove G1 and G2 from the main model to remove the 'prior math grade predicts final math grade' dynamics and instead focus on the students' habits and behaviours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b96e9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing G1 and G2\n",
    "predictors = [col for col in predictors if col not in [\"G1\", \"G2\"]]\n",
    "\n",
    "# one-hot encoding nominal categories\n",
    "X = pd.get_dummies(data[predictors], columns=nominal_cols, drop_first=True)\n",
    "y = data[target].astype(float)\n",
    "\n",
    "print(\"Shape after encoding:\", X.shape)\n",
    "print(\"Shape of target variable\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d624e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e06a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting RF model\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=600,  # a bit higher for stability\n",
    "    max_depth=None,  # letting trees grow; small dataset\n",
    "    min_samples_leaf=2,  # mild regularization\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# I used Chatgpt to help me figure the hyperparater tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c82c8e",
   "metadata": {},
   "source": [
    "### Doing Permutation importance to find top important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance values\n",
    "fi = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "# Show top 15\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=fi.head(15).values, y=fi.head(15).index, palette=\"viridis\")\n",
    "plt.xlabel(\"Random Forest Feature Importance\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Top 15 Features Predicting Final Grade (G3)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also print top 15\n",
    "print(fi.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18210617",
   "metadata": {},
   "source": [
    "Based on the feature importance plot above, we can see that a student's absences and failures play a relatively important role in their final Math grade.\n",
    "\n",
    "\n",
    "For my analysis, I am going to choose 'absence' and 'studytime' and examine their effects using three interpretability tools. The first, A one-dimensional Partial Dependence Plot (PDP) will help show me the average effect of a feature on the model’s predictions, marginalizing over all the other features. While PDP is good for getting a global, averaged view, the Individual Conditional Expectation (ICE) will plot the prediction for each individual student as one feature is varied (for instance, absences and studytime), keeping all others fixed. It will essentially help me uncover the interaction effects that PDP averages would hide. The last interpretability tool I will use is Accumulated Local Effects (ALE), which shows the local effect of a feature on predictions. However, unlike the PDP, it will not extrapolate into regions where there is little or missing data, which is helpful in skewed or correlated datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d26bb",
   "metadata": {},
   "source": [
    "### PDP, ICE, ALE plots\n",
    "\n",
    "This is taken fro mthe code template provided but adapted (with the help of Chatgpt 5 to fit my use case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c3d4bd",
   "metadata": {},
   "source": [
    "#### PDP for 'absences'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48090db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the absences column\n",
    "feature_name = \"absences\"  # \"absences\"\n",
    "feature_index = X.columns.get_loc(feature_name)\n",
    "\n",
    "# build a sensible grid (use the actual observed unique values, sorted)\n",
    "# if there are many unique counts, you can thin it with slicing\n",
    "vals = np.sort(X[feature_name].unique())\n",
    "feature_values = vals  # or vals[::2] to thin\n",
    "\n",
    "# Initialize array to store average predictions\n",
    "average_predictions = np.zeros_like(feature_values, dtype=float)\n",
    "\n",
    "# Duplicate the dataset to modify feature values\n",
    "X_modified = X.copy()\n",
    "\n",
    "# Loop over feature values\n",
    "for i, value in enumerate(feature_values):\n",
    "    # Set the chosen feature to the current value for all instances\n",
    "    X_modified.iloc[:, feature_index] = value\n",
    "\n",
    "    # Predict using the modified dataset\n",
    "    preds = rf.predict(X_modified)\n",
    "\n",
    "    # Calculate average prediction for the current feature value\n",
    "    average_predictions[i] = preds.mean()\n",
    "\n",
    "# Plot the partial dependence for the chosen feature (absences)\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(feature_values, average_predictions, linewidth=2)\n",
    "plt.xlabel(\"Absences (count)\")\n",
    "plt.ylabel(\"Average predicted final grade (G3)\")\n",
    "plt.title(\"Partial Dependence — Absences\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe1db26",
   "metadata": {},
   "source": [
    "#### ICE for 'absence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e65dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf, X, [\"absences\"], kind=\"both\", subsample=80, grid_resolution=50, n_jobs=-1, ax=ax\n",
    ")\n",
    "plt.title(\"ICE + PDP — Absences\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b07672d",
   "metadata": {},
   "source": [
    "#### ALE for 'absence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ale_plot(\n",
    "    rf,\n",
    "    X_train,\n",
    "    \"absences\",\n",
    "    bins=10,\n",
    "    monte_carlo=True,\n",
    "    monte_carlo_rep=30,\n",
    "    monte_carlo_ratio=0.5,\n",
    ")\n",
    "\n",
    "fig = ax.get_figure()  # get parent figure\n",
    "fig.set_size_inches(10, 15)  # resize figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bc753c",
   "metadata": {},
   "source": [
    "The curve from the PDP is non-linear. It rises quickly from 0 to around 2–3 absences, then steadily drops and flattens out after about 20 absences. The small rise at very low absences could just be because there aren’t many students with zero absences. After that, the expected pattern shows up — more absences = lower grades. The model predicts higher grades for students with just a few absences, but as absences increase (beyond 3 to 5), predicted grades drop. After around 20 absences, the curve levels off and stays pretty flat at just over 10.5.\n",
    "\n",
    "This makes sense. Students with low absences generally perform better. As absences go up, performance tends to drop. And once attendance is poor enough, extra absences don’t change much.\n",
    "\n",
    "The ICE plot shows the same trend (orange line), but we can also see that students differ a lot. Some students’ grades fall sharply with just a few absences. Others stay flat, suggesting absences don’t affect them as much.\n",
    "\n",
    "So while the PDP gives the average decline, the ICE plot shows that absences matter much more for some students than others.\n",
    "\n",
    "The ALE plot is also consistent. Students with very few absences tend to do slightly above average, but grades start dropping once absences pass about 5 to 7 days. After 20, the negative effect levels off, so more absences don’t make a big additional difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4185df82",
   "metadata": {},
   "source": [
    "#### PDP for 'studytime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d065e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the absences column\n",
    "feature_name = \"studytime\"  # \"absences\"\n",
    "feature_index = X.columns.get_loc(feature_name)\n",
    "\n",
    "# build a sensible grid (use the actual observed unique values, sorted)\n",
    "# if there are many unique counts, you can thin it with slicing\n",
    "vals = np.sort(X[feature_name].unique())\n",
    "feature_values = vals  # or vals[::2] to thin\n",
    "\n",
    "# Initialize array to store average predictions\n",
    "average_predictions = np.zeros_like(feature_values, dtype=float)\n",
    "\n",
    "# Duplicate the dataset to modify feature values\n",
    "X_modified = X.copy()\n",
    "\n",
    "# Loop over feature values\n",
    "for i, value in enumerate(feature_values):\n",
    "    # Set the chosen feature to the current value for all instances\n",
    "    X_modified.iloc[:, feature_index] = value\n",
    "\n",
    "    # Predict using the modified dataset\n",
    "    preds = rf.predict(X_modified)\n",
    "\n",
    "    # Calculate average prediction for the current feature value\n",
    "    average_predictions[i] = preds.mean()\n",
    "\n",
    "# Plot the partial dependence for the chosen feature (absences)\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(feature_values, average_predictions, linewidth=2)\n",
    "plt.xlabel(\"Study Time\")\n",
    "plt.ylabel(\"Average predicted final grade (G3)\")\n",
    "plt.title(\"Partial Dependence — Study Time\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286aa25",
   "metadata": {},
   "source": [
    "#### ICE for 'studytime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "PartialDependenceDisplay.from_estimator(\n",
    "    rf,\n",
    "    X,\n",
    "    [\"studytime\"],\n",
    "    kind=\"both\",\n",
    "    subsample=80,\n",
    "    grid_resolution=50,\n",
    "    n_jobs=-1,\n",
    "    ax=ax,\n",
    ")\n",
    "plt.title(\"ICE + PDP — Studytime\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ceecb7",
   "metadata": {},
   "source": [
    "#### ALE for 'studytime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0237661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1D ALE: Absences\n",
    "ax = ale_plot(\n",
    "    rf,\n",
    "    X_train,\n",
    "    \"studytime\",\n",
    "    bins=10,\n",
    "    monte_carlo=True,\n",
    "    monte_carlo_rep=30,\n",
    "    monte_carlo_ratio=0.5,\n",
    ")\n",
    "\n",
    "fig = ax.get_figure()  # get parent figure\n",
    "fig.set_size_inches(10, 15)  # resize figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b28dc",
   "metadata": {},
   "source": [
    "From the PDP plot, I can see that average predicted grades stay flat when studytime is around 1–2 hours, but then jump up sharply once studytime goes beyond 2. The more studytime, the higher the predicted grade. This makes sense — more time studying usually means better understanding of the material.\n",
    "\n",
    "The ICE plot confirms the same overall pattern (orange line), but also shows how much students differ. Some students get a big boost in predicted grades as they study more, while others barely improve. So the effect of studytime isn’t the same for everyone.\n",
    "\n",
    "I can see a similar trend from the ALE plot but with a smoother curve. Instead of a sudden jump at 2, it shows a more gradual rise as studytime increases. This happens because ALE corrects for correlations (students who study more may also differ on other things)- thus avoiding the the sharp jump that is visible in the PDP and giving it a cleaner view of the effect.\n",
    "\n",
    "Overall, we can evidently see that more studytime is linked to better performance. PDP shows the sharp average jump, ICE shows that not all students benefit equally, and ALE shows the gradual upward slope once we account for correlations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c59fee0",
   "metadata": {},
   "source": [
    "So far, the PDP, ICE, and ALE plots for absences and studytime on their own give us a good idea of how each feature affects predicted grades individually. But in reality, these factors don’t act in isolation — how much time a student studies might matter differently depending on how often they miss class. To capture this kind of interaction, we need to look at both features together. Thus, in the setion below, I also create the 2D ALE plot to understand the dynamics of both my chosen features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a22658",
   "metadata": {},
   "source": [
    "### 2D ALE plot for absence and studytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f061b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ale_plot(rf, X_train, [\"absences\", \"studytime\"], bins=10, monte_carlo=True)\n",
    "fig = ax.get_figure()\n",
    "fig.set_size_inches(8, 6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab4a40f",
   "metadata": {},
   "source": [
    "From the 2D ALE plot, I see that students with high absences and low studytime do the worst (blue area). On the flip side, students with higher studytime and only moderate absences do better (red area). Either extreme is bad — very high absences or very low studytime both push grades down.\n",
    "\n",
    "The 1D ALE plots already showed this: more absences hurt, more studytime helps. The 2D version just makes clear how the two interact.\n",
    "\n",
    "One thing that stands out is the very top-left corner (low absences + very high studytime). It shows a neutral or even slightly negative effect. That’s probably because there aren’t many students in this group, so the estimates get noisy. It’s similar to what we saw in the PDP for absences, where the tiny bump at zero absences was likely due to very few students falling into that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b066d",
   "metadata": {},
   "source": [
    "Overall, the plots clearly show that, both absences and studytime, play an important role in predicting grades. Low absences and higher studytime are linked to better performance, while skipping too many classes or barely studying drags grades down. The PDPs gave the big picture averages, the ICE plots showed how students differ, and the ALE plots helped clean up the effects and reveal the interactions. Simply put, showing up and putting in the study hours really does matter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
