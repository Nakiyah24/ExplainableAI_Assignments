{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae1b5d3",
   "metadata": {},
   "source": [
    "# Assignment 10\n",
    "## Nakiyah Dhariwala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a513b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4724d",
   "metadata": {},
   "source": [
    "### Original naive method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6233800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_policy(robot_pos, dirt_map):\n",
    "    \"\"\"\n",
    "    Write your cleaning policy here!\n",
    "\n",
    "    This example is very simple. It cleans if on dirt, otherwise it moves randomly.\n",
    "\n",
    "    Args:\n",
    "        robot_pos: [row, col] - Current position of the robot\n",
    "        dirt_map: 2D numpy array where 1 means dirt\n",
    "\n",
    "    Returns:\n",
    "        action: Integer 0-4 where:\n",
    "            0: Move Up\n",
    "            1: Move Right\n",
    "            2: Move Down\n",
    "            3: Move Left\n",
    "            4: Clean\n",
    "    \"\"\"\n",
    "    # If on dirt, clean it\n",
    "    if dirt_map[tuple(robot_pos)] == 1:\n",
    "        return 4\n",
    "\n",
    "    # Otherwise, move randomly\n",
    "    return np.random.randint(0, 4)  # Random direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2cd8c",
   "metadata": {},
   "source": [
    "When I ran the original naive base code above, I could evidently see that robot behaved very randomly. If it was in one part of the grid, it continued to stay in that area, moving over the same few cells randomly before moving to another area completely. Even when it moved over to another quadrant/area, it did not follow any pattern/direction. This is also quite evident because the naive code uses np.random.randint(0, 4).\n",
    "\n",
    "Thus, based on these movements, the robot only cleans when it happens to land on a dirty tile, but it makes no effort to actually look for dirt. Because of this, it wastes a lot of steps moving back and forth over already clean areas. Sometimes it even fails to clean all 20 dirt tiles within the 200-step limit because it gets “stuck” moving randomly instead of exploring the rest of the grid efficiently. \n",
    "\n",
    "Overall, it was slow, repetitive, and unpredictable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49832800",
   "metadata": {},
   "source": [
    "### Section 2: Explain your Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b7eaeb",
   "metadata": {},
   "source": [
    "#### 2.1 My policy - Greedy Nearest-Dirt Policy with light memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff3df7",
   "metadata": {},
   "source": [
    "My improved policy is a nearest-dirt strategy with a little bit of memory. The idea is that at every step, the robot either cleans the tile it’s standing on or walks directly toward the closest piece of dirt. In addition, I store the current target in a small global variable so once the robot picks a dirt tile to chase, it sticks with it until it's gone.\n",
    "\n",
    "This ended up working really well — instead of wandering around like the baseline, the robot always has a goal and reliably cleans all 20 tiles in approximately 51 to 60 steps. My personal best was 51"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6320b9e",
   "metadata": {},
   "source": [
    "#### 2.2 Code with comments and a docstring included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51394362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the current target across calls\n",
    "_last_target = None\n",
    "\n",
    "\n",
    "def cleaning_policy(robot_pos, dirt_map):\n",
    "    \"\"\"\n",
    "    Simple nearest-dirt policy with a bit of memory.\n",
    "    \"\"\"\n",
    "    global _last_target\n",
    "    r, c = robot_pos\n",
    "\n",
    "    # Clean if we're standing on dirt\n",
    "    if dirt_map[r, c] == 1:\n",
    "        _last_target = None  # reset target after cleaning\n",
    "        return 4\n",
    "\n",
    "    # Pick a new target if we don't have one or if it's already clean\n",
    "    if _last_target is None or dirt_map[_last_target] == 0:\n",
    "        dirt_positions = np.argwhere(dirt_map == 1)\n",
    "\n",
    "        # nothing left to clean\n",
    "        if len(dirt_positions) == 0:\n",
    "            return 0\n",
    "\n",
    "        # compute Manhattan distance to every dirt tile\n",
    "        dists = np.abs(dirt_positions[:, 0] - r) + np.abs(dirt_positions[:, 1] - c)\n",
    "\n",
    "        # choose the nearest dirt tile\n",
    "        nearest_idx = np.argmin(dists)\n",
    "        _last_target = tuple(dirt_positions[nearest_idx])\n",
    "\n",
    "    # move one step toward the target\n",
    "    tr, tc = _last_target\n",
    "    dr, dc = tr - r, tc - c\n",
    "\n",
    "    # move along whichever direction gets us closer faster\n",
    "    if abs(dr) >= abs(dc) and dr != 0:\n",
    "        return 2 if dr > 0 else 0\n",
    "    elif dc != 0:\n",
    "        return 1 if dc > 0 else 3\n",
    "    else:\n",
    "        # rare case: target disappeared before we reached it\n",
    "        _last_target = None\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a59fa1",
   "metadata": {},
   "source": [
    "#### 2.3 Discuss your design choices\n",
    "\n",
    "I wanted something that was simple but still way better than the random baseline. So my code:\n",
    "\n",
    "- Aims for the nearest dirt:\n",
    "Since the robot can see the whole map, ignoring that information felt wasteful. A nearest-dirt approach means the robot’s steps actually count toward the goal.\n",
    "\n",
    "- Adds a tiny bit of memory:\n",
    "Without remembering the current target, the robot might keep switching between equally close dirt tiles and never actually reach one. Tracking _last_target fixes that so that the robot commits to a choice until it cleans it.\n",
    "\n",
    "- Uses Manhattan Distance: \n",
    "Since the robot can only move up, down, left, and right, Manhattan distance matches the true movement cost. After trying a few variations, I also kept the movement rule simple by moving along whichever axis has the larger distance so the robot doesn’t zig-zag or take odd paths.\n",
    "\n",
    "Overall, I chose this design because it’s simple, easy to interpret, and directly matches the goal of cleaning dirt quickly. Using Manhattan distance makes sense on a grid, and the memory variable keeps the robot from making unstable decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a346abd",
   "metadata": {},
   "source": [
    "#### Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb33de6",
   "metadata": {},
   "source": [
    "#### 3.1: Compare your policy to the baseline\n",
    "\n",
    "Compared to the baseline using the naive approach, this policy is a lot more efficient. Instead of randomly wandering around, it finishes in around 55-56 steps on average, below the 200-step limit. Even though my approach isn’t perfectly optimal and lags bhind the top scorers, it consistently outperforms the random policy by a huge gap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abadd505",
   "metadata": {},
   "source": [
    "#### 3.2: Analyze Failure Cases\n",
    "\n",
    "One issue with my policy is that it isn’t always fully thorough in one area before moving on. Sometimes the robot cleans most of the dirt in a quadrant but accidentally leaves behind one or two spots. Because it always goes to the nearest dirt, it might see something slightly closer in another quadrant and head there instead. Later, it realizes it missed those earlier tiles and has to walk back to clean them. This back-and-forth doesn’t break the policy, but it does make it a little less efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf89060",
   "metadata": {},
   "source": [
    "#### 3.3: Suggest further improvements\n",
    "\n",
    "Because of the failure case mentioned above, one improvement I would want is to make the policy a bit more aware of clusters of dirt, or to introduce some kind of quadrant-based sweeping. Right now, the robot always picks the single nearest dirt tile, which works well most of the time but can cause it to bounce between areas.\n",
    "\n",
    "Instead if the robot could \"efficiently\" look for clusters of dirt tiles that are close to each other and treat them as a group, it could stay in that area and clean all the nearby dirt before moving to a different part of the grid. Similarly, I think a simple quadrant-sweeping rule could help the robot finish an entire section of the grid rather than leaving behind stray tiles. Both of these changes would make its path more consistent and reduce the extra steps caused by backtracking.\n",
    "\n",
    "However, when I tried adding cluster scoring or quadrant rules, the robot ended up skipping closer dirt and making less efficient choices. The extra logic actually made things worse by creating longer routes and unnecessary backtracking. So even though the ideas make sense, my attempts hurt performance, which is why I stuck with the simpler nearest-dirt approach for now. Nonethless I do think this should (if implemented correctly) optimize the cleaning. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
